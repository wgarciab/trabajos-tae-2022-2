---
title: "Análisis de resultados escolares con reducción de la dimensionalidad y agrupamiento"
author:
  - Amilder Stewin Ospina Tobon
  - Daniel Torres Aguirre
  - Wilmar Andres Garcia Bedoya
date: '2022-09-06'
output: html_document
---

# Introducción
En este informe, examinaremos una base de datos de universidades de estados unidos, proporcionada por el Departamento de Educación de los Estados Unidos. Nuestro objetivo será realizar un agrupamiento de estas universidades, para luego caracterizar cada grupo, y determinar qué hace que un grupo sea mejor que otro.

# Objetivo 
El objetivo de este trabajo es realizar una segmentacion en grupos de universidades en base a las caracteristicas de interes de nuestro analisis, nuestro interes es el analisis del desempeño academico y como esto podria estar relacionado con el coste de las matriculas, la cantidad de estudiantes que reciben apoyos financieros y las deudas de estos estudiantes, ademas de la cantidad des estudiantes que hay por universidad.

# Carga y limpieza de datos
Inicialmente, cargamos todos los datos. La base de datos contiene 7804 observaciones de 1725 variables.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(readr)
colleges <- read_csv("exercises-cluster-analysis-exercise-2/CollegeScorecard.csv", na = c("NULL", "PrivacySuppressed"))
dictionary <- read_csv("exercises-cluster-analysis-exercise-2/CollegeScorecardDataDictionary-09-12-2015.csv")
dim(colleges)
#str(colleges)
#summary(colleges)
```
Podemos examinar las primeras 6 observaciones para hacernos una idea de la estructura de la base de datos

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)
#kable(head(colleges))
DT::datatable(head(colleges), options = list(
        scrollX = TRUE,
        scrollY = "250px"))
```

Lo que haremos a continuación será quitar las columnas nulas, es decir, aquellas variables para las cuales no hay información. De esta forma, nuestra base de datos se reduce de 1725 a 551 columnas.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#sum(is.na(colleges$mn_earn_wne_p8))
colleges <- Filter(function(x)!all(is.na(x)), colleges)
dim(colleges)
#sapply(colleges, function(x) sum(is.na(x)))
```

Seleccionamos variables relevantes para nuestro problema, y las guardamos en un nuevo dataframe que contiene unicamente esas variables.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(dplyr)
college_subset <- colleges %>% 
    select(OPEID, INSTNM, CITY, STABBR, ZIP, 
           CONTROL, DISTANCEONLY, CITY, TUITFTE, ADM_RATE_ALL,
           C150_4, DEBT_MDN,SAT_AVG, PCTFLOAN, UGDS, NPT4_PUB, NPT4_PRIV)
```

Las variables seleccionados fueron las siguientes

```{r, echo=FALSE, message=FALSE, warning=FALSE}
kable(dictionary %>% filter(`VARIABLE NAME` %in% names(college_subset)) %>% select('NAME OF DATA ELEMENT', 'VARIABLE NAME'))
```

Veamos cuantos nulos hay en cada columna

```{r, echo=FALSE, message=FALSE, warning=FALSE}
kable(sapply(college_subset, function(x) sum(is.na(x))))
```

Reemplazamos los valores nulos de cada columna por la mediana de los demas valores existentes en esa columna.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(plyr)
library(dplyr)

college_subset2 <- college_subset[6:16]

median_values <- college_subset2 %>% 
    summarise_each(funs(median(., na.rm = TRUE)))

#median_values

college_subset2 <- college_subset2 %>%
    mutate_each(funs(if_else(is.na(.), median(., na.rm = TRUE), .)))

```

De esta manera, el número de nulos en todas las columnas queda en cero.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
kable(sapply(college_subset2, function(x) sum(is.na(x))))
```

# PCA (Análisis de componentes principales)

Para realizar el agrupamiento, únicamente utilizaremos las últimas 11 variables, ya que las primeras 5, tales como el nombre de la institución o su código, no nos resultan útiles para el clustering.
No se trabajó con las variables originales ya que previamente se seleccionaron manualmente las variables mas relevantes para el analisis de nuestro objetivo 

En la siguiente matrix de correlación podemos ver que no hay una correlación fuerte entre ninguna de las variables.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(corrplot)
cor_matrix <- cor(college_subset2)
kable(round(cor_matrix, 2))
corrplot(cor_matrix)
```

Con las primeras 9 variables de estas 11, se explica un 92.9% de la varianza total. 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
college_subset2_cent <- scale(college_subset2,center = TRUE,scale = TRUE)
college_pca <- prcomp(college_subset2_cent)
(summary(college_pca))
```

Sin embargo, las usaremos todas, porque es de nuestro interés analizarlas todas.

# Clustering

## Seleccion del numero de clusters

Para seleccionar el número adecuado de clusters, usaremos el método de Elbow. Veamos la curva generada:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(broom)
library(tidyr)
library(dplyr)
set.seed(1234)
kclusts <- data.frame(k=4:20) %>% 
    group_by(k) %>% 
    do(kclust = kmeans(college_subset2, .$k))

clusters <- kclusts %>% group_by(k) %>% do(tidy(.$kclust[[1]]))
assignments <- kclusts %>% group_by(k) %>% do(augment(.$kclust[[1]], college_subset2))
clusterings <- kclusts %>% group_by(k) %>% do(glance(.$kclust[[1]]))

library(ggfortify)
ggplot(clusterings, aes(k, tot.withinss)) +
    geom_line(color = "blue", alpha = 0.5, size = 2) +
    geom_point(size = 0.8)
```

De acuerdo al metodo de Elbow, el número ideal de clusters es 9, ya que se puede apreciar un "codo" en la gráfica cerca a k = 9, a pesar de que en k=7 hay un codo muy pronunciado, consideramos que entre k=7 y k=9 todavia hay una mejora significativa, y a partir de k=9 las mejoras dejan de ser siginificativas ya que cada vez hay una pendiente menor.

## Agrupamiento con K-means

Para realizar el agrupamiento, utilizaremos k-means con 9 clústers. El resultado del agrupamiento de puede apreciar en la siguiente figura

```{r, echo=FALSE, message=FALSE, warning=FALSE}
set.seed(1234)
autoplot(kmeans(college_subset2, 9), data = college_subset2, size = 3, alpha = 0.5) +
    ggtitle("K-Means Clustering of College Scorecard Data") +
    theme(legend.position="none")

my_kmeans <- kmeans(college_subset2, 9)
```

## Caracterización de los clusters

A continuación, revisaremos cada uno de los clusters y examinaremos sus principales características. En el siguiente gráfico, llamado gráfico de radar, se presentan las medias de los 9 clusters en cada una de las variables, normalizadas entre 0 y 1. Los valores más alejados del centro representan valores más grandes.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#colleges <- colleges %>% 
#    mutate(cluster = my_kmeans$cluster) 

college_subset2 = data.frame(college_subset2)
college_subset2 <- college_subset2 %>% 
    mutate(cluster = my_kmeans$cluster) 

#colleges %>%
#    filter(cluster == 1) %>%
#    select(INSTNM)

cluster1 <- college_subset2 %>%
    filter(cluster == 1) %>%
    select(
           CONTROL, DISTANCEONLY, TUITFTE, ADM_RATE_ALL,
           C150_4, DEBT_MDN, NPT4_PUB, NPT4_PRIV, DEBT_MDN,SAT_AVG,
           PCTFLOAN, UGDS)

cluster2 <- college_subset2 %>%
    filter(cluster == 2) %>%
    select(
           CONTROL, DISTANCEONLY, TUITFTE, ADM_RATE_ALL,
           C150_4, DEBT_MDN, NPT4_PUB, NPT4_PRIV, DEBT_MDN,SAT_AVG,
           PCTFLOAN, UGDS)

cluster3 <- college_subset2 %>%
    filter(cluster == 3) %>%
    select(
           CONTROL, DISTANCEONLY, TUITFTE, ADM_RATE_ALL,
           C150_4, DEBT_MDN, NPT4_PUB, NPT4_PRIV, DEBT_MDN,SAT_AVG,
           PCTFLOAN, UGDS)

cluster4 <- college_subset2 %>%
    filter(cluster == 4) %>%
    select(
           CONTROL, DISTANCEONLY, TUITFTE, ADM_RATE_ALL,
           C150_4, DEBT_MDN, NPT4_PUB, NPT4_PRIV, DEBT_MDN,SAT_AVG,
           PCTFLOAN, UGDS)

cluster5 <- college_subset2 %>%
    filter(cluster == 5) %>%
    select(
           CONTROL, DISTANCEONLY, TUITFTE, ADM_RATE_ALL,
           C150_4, DEBT_MDN, NPT4_PUB, NPT4_PRIV, DEBT_MDN,SAT_AVG,
           PCTFLOAN, UGDS)

cluster6 <- college_subset2 %>%
    filter(cluster == 6) %>%
    select(
           CONTROL, DISTANCEONLY, TUITFTE, ADM_RATE_ALL,
           C150_4, DEBT_MDN, NPT4_PUB, NPT4_PRIV, DEBT_MDN,SAT_AVG,
           PCTFLOAN, UGDS)

cluster7 <- college_subset2 %>%
    filter(cluster == 7) %>%
    select(
           CONTROL, DISTANCEONLY, TUITFTE, ADM_RATE_ALL,
           C150_4, DEBT_MDN, NPT4_PUB, NPT4_PRIV, DEBT_MDN,SAT_AVG,
           PCTFLOAN, UGDS)

cluster8 <- college_subset2 %>%
    filter(cluster == 8) %>%
    select(
           CONTROL, DISTANCEONLY, TUITFTE, ADM_RATE_ALL,
           C150_4, DEBT_MDN, NPT4_PUB, NPT4_PRIV, DEBT_MDN,SAT_AVG,
           PCTFLOAN, UGDS)

cluster9 <- college_subset2 %>%
    filter(cluster == 9) %>%
    select(
           CONTROL, DISTANCEONLY, TUITFTE, ADM_RATE_ALL,
           C150_4, DEBT_MDN, NPT4_PUB, NPT4_PRIV, DEBT_MDN,SAT_AVG,
           PCTFLOAN, UGDS)


# cluster10 <- college_subset2 %>%
#     filter(cluster == 10) %>%
#     select(
#            CONTROL, DISTANCEONLY, TUITFTE, ADM_RATE_ALL,
#            C150_4, DEBT_MDN, NPT4_PUB, NPT4_PRIV, DEBT_MDN,SAT_AVG,
#            PCTFLOAN, UGDS)

# cluster11 <- college_subset2 %>%
#     filter(cluster == 11) %>%
#     select(
#            CONTROL, DISTANCEONLY, TUITFTE, ADM_RATE_ALL,
#            C150_4, DEBT_MDN, NPT4_PUB, NPT4_PRIV, DEBT_MDN,SAT_AVG,
#            PCTFLOAN, UGDS)

# cluster12 <- college_subset2 %>%
#     filter(cluster == 12) %>%
#     select(
#            CONTROL, DISTANCEONLY, TUITFTE, ADM_RATE_ALL,
#            C150_4, DEBT_MDN, NPT4_PUB, NPT4_PRIV, DEBT_MDN,SAT_AVG,
#            PCTFLOAN, UGDS)


#summary(cluster1)
#hist(cluster1$TUITFTE)
#write.csv(cluster1,"cluster1.csv", row.names = FALSE)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(fmsb)

#normalize <- function(x) {
#  return((x - min(x)) / (max(x) - min(x)))
#}

cluster1_means = t(colMeans(cluster1[3:11]))
cluster2_means = t(colMeans(cluster2[3:11]))
cluster3_means = t(colMeans(cluster3[3:11]))
cluster4_means = t(colMeans(cluster4[3:11]))
cluster5_means = t(colMeans(cluster5[3:11]))
cluster6_means = t(colMeans(cluster6[3:11]))
cluster7_means = t(colMeans(cluster7[3:11]))
cluster8_means = t(colMeans(cluster8[3:11]))
cluster9_means = t(colMeans(cluster9[3:11]))
#cluster10_means = t(colMeans(cluster10[3:11]))
#cluster11_means = t(colMeans(cluster11[3:11]))
#cluster12_means = t(colMeans(cluster12[3:11]))


df = data.frame()
df = rbind(df, cluster1_means)
df = rbind(df, cluster2_means)
df = rbind(df, cluster3_means)
df = rbind(df, cluster4_means)
df = rbind(df, cluster5_means)
df = rbind(df, cluster6_means)
df = rbind(df, cluster7_means)
df = rbind(df, cluster8_means)
df = rbind(df, cluster9_means)
#df = rbind(df, cluster10_means)
#df = rbind(df, cluster11_means)
#df = rbind(df, cluster12_means)

df_norm <- as.data.frame(apply(df[, 1:9], 2, function(x) (x - min(x))/(max(x)-min(x))))

df_norm <- rbind(rep(max(df_norm), 9), rep(0, 9), df_norm)

radarchart(df_norm, 
           seg = 9,  # Number of axis segments
           title = "Clusters de universidades",
           pcol = 1:12,
           plwd = 2)

legend(x=1.15, 
       y=1.35, 
       legend = c(1:9),
       bty = "n", pch=20 , col = 1:12, cex = 1.05, pt.cex = 1.5)
```

### Descripcion de los grupos

En el cluster 1, hay una masiva tasa de admisión, cercana al 90%, pero en todos los demás aspectos presenta valores muy bajos. Sus tasas de completación de estudios y número de estudiantes es muy bajo. Como punto positivo, los costos por estudiar en estas instituciones tambien son muy bajos, aunque curiosamente, es un poco más costoso estudiar en instituciones públicas que en instituciones privadas. Cerca del 50% de los estudiantes recibe préstamos del estado, pero la deuda acumulada es muy baja, lo cual es debido posiblemente a los bajos costos de estas universidades. Sus puntajes de admision tambien son muy bajos. Se podría decir que a estas instituciones se puede entrar muy fácilmente.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#para visualizar cada cluster por separado, cambiar el siguiente numero:
cluster_number = 1
df_cluster_mean = df_norm[cluster_number+2,]
df_cluster_mean <- rbind(rep(max(df_norm), 9), rep(0, 9), df_cluster_mean)

radarchart(df_cluster_mean, 
           seg = 9,  # Number of axis segments
           title = "Cluster 1",
           pcol = 1,
           plwd = 2)

```

El cluster 2 tiene los puntajes de admision mas altos, al igual que la tasa de completación de estudios mas alta, pero su tasa de admisión es la mas baja, y cuenta con pocos estudiantes. Cerca del 80% de los estudiantes recibe préstamos del estado, y además, el costo de estudiar en universidades privadas de este grupo es excesivamente alto, razón por la cual se puede explicar que la deuda acumulada sea bastante alta también. Se podría decir que es un grupo de universidades exclusivo.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#para visualizar cada cluster por separado, cambiar el siguiente numero:
cluster_number = 2
df_cluster_mean = df_norm[cluster_number+2,]
df_cluster_mean <- rbind(rep(max(df_norm), 9), rep(0, 9), df_cluster_mean)

radarchart(df_cluster_mean, 
           seg = 9,  # Number of axis segments
           title = "Cluster 2",
           pcol = 1,
           plwd = 2)

```

El cluster 3 es más interesante que los anteriores. Su número de estudiantes es muy bajo, pero en todos los demás aspectos es bastante equilibrado. El costo de estudiar en instituciones privadas de este grupo es intermedio, y en instituciones públicas es un poco inferior. Cerca del 50% de los estudiantes de este grupo tienen préstamos, pero aun así, la deuda acumulada no es muy grande. Los puntajes de admisión son relativamente altos, y la tasa de admisión está derca del 20%. La tasa de completación está cerca del 40%

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#para visualizar cada cluster por separado, cambiar el siguiente numero:
cluster_number = 3
df_cluster_mean = df_norm[cluster_number+2,]
df_cluster_mean <- rbind(rep(max(df_norm), 9), rep(0, 9), df_cluster_mean)

radarchart(df_cluster_mean, 
           seg = 9,  # Number of axis segments
           title = "Cluster 3",
           pcol = 1,
           plwd = 2)

```

El cluster #4 está caracterizado por unos niveles de admisión (ADM_RATE_ALL) reducidos (40% aprox.) y una cantidad de estudiantes matriculados (UGDS) muy altas a comparación del resto de clusters. Los estudiantes en estas universidades parecen estar caracterizados por un nivel académico bueno en pruebas SAT (SAT_AVG) y niveles aceptables (45%) en cuanto al avance de sus carreras en el plazo estipulado se refiere (C150_4). Podemos notar tambén que a un nivel de préstamos, que la mayoría  de estudiantes no ha recibido subsidios o prestamos gubernametales (PCTFLOAN) y esto parece estar reflejado en el monto de deuda gubernamental acumulada (DEBT_MDN) registrada en dicha universidad que es bajo. Estas universidades en sí no parecen ser muy caras como se puede ver en la variable TUITFTE, pero sí parecen ser bastante costoso estudiar en ellas, aspecto evidenciado en los costos promedios totales en universidades públicas (NPT4_PUB)(con un 100% aprox.). En universidades privadas (NPT4_PRIV) no parece ser tan alto. 
En base a la cantidad de estudiantes que logran entrar, al rendimiento académico de éstos y el coste promedio de estudiar en ellas, las instituciones formadas por éste cluster parecen ser universidades de media/alta calidad y para estudiantes con un estatus social medio/alto.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#para visualizar cada cluster por separado, cambiar el siguiente numero:
cluster_number = 4
df_cluster_mean = df_norm[cluster_number+2,]
df_cluster_mean <- rbind(rep(max(df_norm), 9), rep(0, 9), df_cluster_mean)

radarchart(df_cluster_mean, 
           seg = 9,  # Number of axis segments
           title = "Cluster 4",
           pcol = 1,
           plwd = 2)

```

El cluster 5 podemos observar un nivel de admision medianamente alto (cercano al 70%), mientras que en el promedio de las pruebas de admision sat observamos un valor muy bajo, como tambien un desempeño en la completacion de la carrera en un tiempo especifico igualmente bajo, ahora viendo los aspectos economicos de las universidades, el coste de estudiar en una universidad privado como en una universidad publica es bastante parecido (rondando entre el 60% y el 50%), sin embargo los ingresos netos de matricula por los estudiantes es bastante bajo, ademas se tienen valores bastante altos tanto en la media de la deuda acumuladad por los estudiantes como en la cantidad de estudiantes que recibieron prestamos federales

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#para visualizar cada cluster por separado, cambiar el siguiente numero:
cluster_number = 5
df_cluster_mean = df_norm[cluster_number+2,]
df_cluster_mean <- rbind(rep(max(df_norm), 9), rep(0, 9), df_cluster_mean)

radarchart(df_cluster_mean, 
           seg = 9,  # Number of axis segments
           title = "Cluster 5",
           pcol = 1,
           plwd = 2)

```

El cluster 6 es bastante peculiar, ya que teniendo un nivel de admision bastante alto (cerca al 90%), en los otros aspectos academicos podemos ver un bajo rendimiento en las pruebas de admsion sat y en el desempeño en la completacion de la carrera en el tiempo en especificado
en otros aspectos podemos ver que el coste de estudiar en una universidad publica es bastante bajo,como tambien los ingresos netos por matricula por estudiante son bastante bajos, ademas de que el valor de la media de la deuda acumulada por los estudiantes, como el numero de estudiantes que recibieron prestamos federales es bastante bajo 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#para visualizar cada cluster por separado, cambiar el siguiente numero:
cluster_number = 6
df_cluster_mean = df_norm[cluster_number+2,]
df_cluster_mean <- rbind(rep(max(df_norm), 9), rep(0, 9), df_cluster_mean)

radarchart(df_cluster_mean, 
           seg = 9,  # Number of axis segments
           title = "Cluster 6",
           pcol = 1,
           plwd = 2)

```

El cluster 7 se puede caracterizar por tener un nivel de admision bastante alto, cercano al 100%, pero podemos observar que el rendimiento en las pruebas de admision SAT es bastante bajo, lo que impleca que el puntaje necesario para entrar en estas universidades no es muy alto, tambien podemos notar como el desempeño en la completacion de la carrera en el tiempo estimado es bastante bajo
en otros aspectos se puede observar que el coste promedio para estudiar tanto en universidades publicas como privadas lo podemos considerar bajo, como tambien los ingresos obtenidos por estudiantes matriculados es bastante bajo 


```{r, echo=FALSE, message=FALSE, warning=FALSE}
#para visualizar cada cluster por separado, cambiar el siguiente numero:
cluster_number = 7
df_cluster_mean = df_norm[cluster_number+2,]
df_cluster_mean <- rbind(rep(max(df_norm), 9), rep(0, 9), df_cluster_mean)

radarchart(df_cluster_mean, 
           seg = 9,  # Number of axis segments
           title = "Cluster 7",
           pcol = 1,
           plwd = 2)

```



El cluster #8 está caracterizado por una proporción considerable (85% aprox) de estudiantes admitidos (ADM_RATE_ALL) y una muy baja cantidad de estudiantes matriculados en universidades (UGDS) a comparación de otros clusters. En un ámbito académico el cluster no es de destacar, tiene un rendimiento académico (SAT_AVG) muy bajo y el avance esperado de sus estudiantes (C150_4) tampoco es bueno. Interesantemente, notamos que a pesar de que la deuda acumulada de la universidad (DEBT_MDN) y la proporción de estudiantes que han recibido préstamos (PCTFLOAN) es bajo, tanto el coste de matricula (TUITFTE) como el coste de estudiar en las instituciones (NPT4_PUB, NPT4_PRIV) son especialmente altos. 
Teniendo en cuenta la disparidad entre estudiantes endeudados y costos de estudio en las universidades de este cluster, podríamos llegar a inferir que en estas universidades estudian personas con una capacidad adquisitiva suficiente para no tener que costear a crédito sus estudios. 



```{r, echo=FALSE, message=FALSE, warning=FALSE}
#para visualizar cada cluster por separado, cambiar el siguiente numero:
cluster_number = 8
df_cluster_mean = df_norm[cluster_number+2,]
df_cluster_mean <- rbind(rep(max(df_norm), 9), rep(0, 9), df_cluster_mean)

radarchart(df_cluster_mean, 
           seg = 9,  # Number of axis segments
           title = "Cluster 8",
           pcol = 1,
           plwd = 2)

```

El cluster #9 está caracterizado por un ratio de admision de estudiantes (ADM_RATE_ALL) muy alto (casi el 100%) y un . El nivel de los estudiantes en las pruebas SAT es bastante bajo en estas universidades, y su avance esperado en sus carreras (C150_4) también lo es. En su gran mayoría, los alumnos de estas instituciones han recibido prestmamos (PCTFLOAN) federales (casi el 100%), a pesar del bajo coste aparente de matricular en estas (TUITFTE). Aun así podemos observar que el coste total de estudiar en estas universidades es medio para universidades privadas (NPT4_PRIV) y relativamente bajo para las públicas (NPT4_PUB). Finalmente hay que destacar que no hay una cantidad relativamente alta de estudiantes matriculados (UGDS) en este cluster a comparación de otros. Se podría decir, en base al historial crediticio, ratio de admisión, cantidad de estudiantes y desempeño académico, que en este cluster consta de pequeñas universidades publicas y privadas con estudiantes de medios/bajos recursos económicos. 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#para visualizar cada cluster por separado, cambiar el siguiente numero:
cluster_number = 9
df_cluster_mean = df_norm[cluster_number+2,]
df_cluster_mean <- rbind(rep(max(df_norm), 9), rep(0, 9), df_cluster_mean)

radarchart(df_cluster_mean, 
           seg = 9,  # Number of axis segments
           title = "Cluster 9",
           pcol = 1,
           plwd = 2)

```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
college_subset[6:16] <- college_subset[6:16] %>%
    mutate_each(funs(if_else(is.na(.), median(., na.rm = TRUE), .)))

college_subset = data.frame(college_subset)
college_subset <- college_subset %>% 
    mutate(cluster = my_kmeans$cluster) 

```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# generación de los archivoos csv de los clusters
# cluster_full <- college_subset %>%
#     filter(cluster == 9) %>%
#     select(OPEID, INSTNM, CITY, STABBR, ZIP,
#            CONTROL, DISTANCEONLY, TUITFTE, ADM_RATE_ALL,
#            C150_4, DEBT_MDN, NPT4_PUB, NPT4_PRIV, SAT_AVG,
#            PCTFLOAN, UGDS)
# 
# write.csv(cluster_full,"clustersdata/cluster9.csv", row.names = FALSE)
```

## Propuesta de análisis en colombia 

Para el desarrollo de un análisis en colombia, similar al realizado con el dataset College ScoreCard podemos extraer información de las siguientes páginas:

En la página del ministerio de educación nacional(https://hecaa.mineducacion.gov.co/consultaspublicas/content/poblacional/index.jsf) 
podemos encontrar información de los estudiantes inscritos, los estudiantes matriculados, los estudiantes graduados y los
docentes, los cuales se encuentran segmentados por:

|        • Universidades oficiales
|        • Universidades privadas
|        • Mujeres
|        • Hombres
|        • Nivel de formación  


Todos esto por años en específico desde 2016 hasta el 2021.
Además para los docentes también podemos encontrar el área de conocimiento en la que
se encuentran.

También se encuentra la información por IES la cual nos da el número de estudiantes
matriculados, inscritos y admitidos en un año en específico, como también el número total
de docentes con el que cuenta la universidad.

En la página El observatorio de la universidad colombiana
(https://www.universidad.edu.co/evolucion-de-los-resultados-saber-pro-en-todas-las-ies-del-pais-ano-2-020/)
se puede encontrar información
sobre el promedio de las pruebas saber pro por universidad.

Además de esta información se vería necesario recolectar el promedio de los puntajes de
admisión por universidad, además de un promedio del coste de la matrícula de todos los
estudiantes por universidad, la cantidad de estudiantes que cuentan con becas o ayudas del
estado, en caso de las universidades públicas el presupuesto destinado por el estado y por
último los ingresos de la universidad tanto por investigación y extensión como los obtenidos
por la matrícula de los estudiantes

# Referencias

Silge, J. (2016). Exploratory Data Analysis of College Scorecard Data. https://rpubs.com/juliasilge/207156  
Silge, J. (2016). Imputing Missing Values in the College Scorecard Data Via Very Simple Methods. https://rpubs.com/juliasilge/216478

